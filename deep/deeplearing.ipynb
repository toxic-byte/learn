{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bec482b",
   "metadata": {},
   "source": [
    "# config配置管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    \"\"\"配置类，管理所有参数和路径\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 数据路径\n",
    "        self.data_path = \"your_data_file.csv\"\n",
    "        self.output_dir = \"output/\"\n",
    "\n",
    "        # 预处理参数\n",
    "        self.missing_threshold = 0.5\n",
    "        self.correlation_threshold = 0.8\n",
    "\n",
    "        # 分析参数\n",
    "        self.cluster_n = 3\n",
    "        self.test_size = 0.2\n",
    "\n",
    "        # 可视化参数\n",
    "        self.figsize = (12, 8)\n",
    "        self.colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031107e",
   "metadata": {},
   "source": [
    "# dataloader数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3532b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"数据加载器\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(file_path):\n",
    "        \"\"\"加载数据文件\"\"\"\n",
    "        path = Path(file_path)\n",
    "\n",
    "        if path.suffix == '.csv':\n",
    "            return pd.read_csv(file_path)\n",
    "        elif path.suffix in ['.xlsx', '.xls']:\n",
    "            return pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的文件格式: {path.suffix}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data_info(df):\n",
    "        \"\"\"获取数据基本信息\"\"\"\n",
    "        info = {\n",
    "            'shape': df.shape,\n",
    "            'columns': list(df.columns),\n",
    "            'dtypes': df.dtypes.to_dict(),\n",
    "            'memory_usage': df.memory_usage(deep=True).sum()\n",
    "        }\n",
    "        return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7066ac",
   "metadata": {},
   "source": [
    "# preprocess数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd43965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"数据预处理类\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def handle_missing_values(self, df):\n",
    "        \"\"\"处理缺失值\"\"\"\n",
    "        # 删除缺失值过多的列\n",
    "        missing_ratio = df.isnull().sum() / len(df)\n",
    "        cols_to_drop = missing_ratio[missing_ratio > self.config.missing_threshold].index\n",
    "        df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "        # 填充剩余缺失值\n",
    "        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "        df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())\n",
    "        df_clean[categorical_cols] = df_clean[categorical_cols].fillna('Unknown')\n",
    "\n",
    "        return df_clean\n",
    "\n",
    "    def remove_highly_correlated_features(self, df):\n",
    "        \"\"\"移除高度相关的特征\"\"\"\n",
    "        corr_matrix = df.corr().abs()\n",
    "        upper_triangle = corr_matrix.where(\n",
    "            np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "        )\n",
    "\n",
    "        cols_to_drop = [\n",
    "            column for column in upper_triangle.columns \n",
    "            if any(upper_triangle[column] > self.config.correlation_threshold)\n",
    "        ]\n",
    "\n",
    "        return df.drop(columns=cols_to_drop), cols_to_drop\n",
    "\n",
    "    def scale_features(self, df):\n",
    "        \"\"\"标准化数值特征\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        df_scaled = df.copy()\n",
    "        df_scaled[numeric_cols] = self.scaler.fit_transform(df[numeric_cols])\n",
    "        return df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cec76",
   "metadata": {},
   "source": [
    "# analysis数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b57c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class DataAnalyzer:\n",
    "    \"\"\"数据分析器\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def perform_clustering(self, df, n_clusters=None):\n",
    "        \"\"\"执行聚类分析\"\"\"\n",
    "        if n_clusters is None:\n",
    "            n_clusters = self.config.cluster_n\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        X = df[numeric_cols]\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        clusters = kmeans.fit_predict(X)\n",
    "\n",
    "        return clusters, kmeans\n",
    "\n",
    "    def perform_pca(self, df, n_components=2):\n",
    "        \"\"\"执行PCA降维\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        X = df[numeric_cols]\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "        principal_components = pca.fit_transform(X)\n",
    "\n",
    "        return principal_components, pca\n",
    "\n",
    "    def train_classification_model(self, df, target_column):\n",
    "        \"\"\"训练分类模型\"\"\"\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "\n",
    "        # 只保留数值列\n",
    "        X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=self.config.test_size, random_state=42\n",
    "        )\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        return model, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0fa93",
   "metadata": {},
   "source": [
    "# visual可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class DataVisualizer:\n",
    "    \"\"\"数据可视化类\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.setup_plot_style()\n",
    "\n",
    "    def setup_plot_style(self):\n",
    "        \"\"\"设置绘图样式\"\"\"\n",
    "        plt.style.use('default')\n",
    "        sns.set_palette(self.config.colors)\n",
    "\n",
    "    def plot_distributions(self, df, save_path=None):\n",
    "        \"\"\"绘制数值特征的分布图\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        n_cols = 3\n",
    "        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=self.config.figsize)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, col in enumerate(numeric_cols):\n",
    "            if i < len(axes):\n",
    "                df[col].hist(bins=30, ax=axes[i])\n",
    "                axes[i].set_title(f'Distribution of {col}')\n",
    "                axes[i].set_xlabel(col)\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "\n",
    "        # 隐藏多余的子图\n",
    "        for i in range(len(numeric_cols), len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_correlation_heatmap(self, df, save_path=None):\n",
    "        \"\"\"绘制相关性热力图\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        plt.figure(figsize=self.config.figsize)\n",
    "        corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', \n",
    "                   center=0, square=True, fmt=\".2f\")\n",
    "        plt.title('Feature Correlation Heatmap')\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_clustering_results(self, df, clusters, pca_components, save_path=None):\n",
    "        \"\"\"绘制聚类结果\"\"\"\n",
    "        plt.figure(figsize=self.config.figsize)\n",
    "\n",
    "        scatter = plt.scatter(pca_components[:, 0], pca_components[:, 1], \n",
    "                             c=clusters, cmap='viridis', alpha=0.7)\n",
    "        plt.colorbar(scatter)\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.title('Clustering Results (PCA Visualization)')\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcc159",
   "metadata": {},
   "source": [
    "# utils工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "class Logger:\n",
    "    \"\"\"简单的日志记录器\"\"\"\n",
    "\n",
    "    def __init__(self, log_file=\"analysis_log.txt\"):\n",
    "        self.log_file = log_file\n",
    "\n",
    "    def log(self, message):\n",
    "        \"\"\"记录日志\"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_message = f\"[{timestamp}] {message}\"\n",
    "\n",
    "        print(log_message)\n",
    "\n",
    "        with open(self.log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(log_message + '\\n')\n",
    "\n",
    "def save_results(results, file_path):\n",
    "    \"\"\"保存分析结果\"\"\"\n",
    "    path = Path(file_path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 转换numpy类型为Python原生类型\n",
    "    def convert_types(obj):\n",
    "        if isinstance(obj, (np.integer, np.floating)):\n",
    "            return obj.item()\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_types(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_types(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    results = convert_types(results)\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def create_output_directory(config):\n",
    "    \"\"\"创建输出目录\"\"\"\n",
    "    output_dir = Path(config.output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68586b",
   "metadata": {},
   "source": [
    "# main主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82334d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from data_loader import DataLoader\n",
    "from preprocessor import DataPreprocessor\n",
    "from analyzer import DataAnalyzer\n",
    "from visualizer import DataVisualizer\n",
    "from utils import Logger, save_results, create_output_directory\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 初始化组件\n",
    "    logger = Logger()\n",
    "    output_dir = create_output_directory(config)\n",
    "\n",
    "    logger.log(\"开始数据分析流程\")\n",
    "\n",
    "    try:\n",
    "        # 1. 加载数据\n",
    "        logger.log(\"步骤1: 加载数据\")\n",
    "        df = DataLoader.load_data(config.data_path)\n",
    "        data_info = DataLoader.get_data_info(df)\n",
    "        logger.log(f\"数据加载成功: {data_info['shape']}\")\n",
    "\n",
    "        # 2. 数据预处理\n",
    "        logger.log(\"步骤2: 数据预处理\")\n",
    "        preprocessor = DataPreprocessor(config)\n",
    "\n",
    "        # 处理缺失值\n",
    "        df_clean = preprocessor.handle_missing_values(df)\n",
    "        logger.log(f\"缺失值处理完成，原始形状: {df.shape}, 清理后: {df_clean.shape}\")\n",
    "\n",
    "        # 移除高度相关特征\n",
    "        df_final, dropped_cols = preprocessor.remove_highly_correlated_features(df_clean)\n",
    "        logger.log(f\"移除高度相关特征: {dropped_cols}\")\n",
    "\n",
    "        # 特征标准化\n",
    "        df_scaled = preprocessor.scale_features(df_final)\n",
    "        logger.log(\"特征标准化完成\")\n",
    "\n",
    "        # 3. 数据分析\n",
    "        logger.log(\"步骤3: 数据分析\")\n",
    "        analyzer = DataAnalyzer(config)\n",
    "\n",
    "        # 聚类分析\n",
    "        clusters, kmeans_model = analyzer.perform_clustering(df_scaled)\n",
    "        logger.log(f\"聚类分析完成，找到 {len(set(clusters))} 个簇\")\n",
    "\n",
    "        # PCA降维\n",
    "        pca_components, pca_model = analyzer.perform_pca(df_scaled)\n",
    "        logger.log(\"PCA分析完成\")\n",
    "\n",
    "        # 4. 可视化\n",
    "        logger.log(\"步骤4: 生成可视化\")\n",
    "        visualizer = DataVisualizer(config)\n",
    "\n",
    "        # 绘制分布图\n",
    "        visualizer.plot_distributions(\n",
    "            df_final, \n",
    "            save_path=output_dir / \"distributions.png\"\n",
    "        )\n",
    "\n",
    "        # 绘制相关性热力图\n",
    "        visualizer.plot_correlation_heatmap(\n",
    "            df_final,\n",
    "            save_path=output_dir / \"correlation_heatmap.png\"\n",
    "        )\n",
    "\n",
    "        # 绘制聚类结果\n",
    "        visualizer.plot_clustering_results(\n",
    "            df_scaled, clusters, pca_components,\n",
    "            save_path=output_dir / \"clustering_results.png\"\n",
    "        )\n",
    "\n",
    "        # 5. 保存结果\n",
    "        logger.log(\"步骤5: 保存结果\")\n",
    "        results = {\n",
    "            'data_info': data_info,\n",
    "            'preprocessing': {\n",
    "                'original_shape': df.shape,\n",
    "                'cleaned_shape': df_clean.shape,\n",
    "                'final_shape': df_final.shape,\n",
    "                'dropped_columns': dropped_cols\n",
    "            },\n",
    "            'clustering': {\n",
    "                'n_clusters': len(set(clusters)),\n",
    "                'cluster_sizes': pd.Series(clusters).value_counts().to_dict()\n",
    "            },\n",
    "            'pca': {\n",
    "                'explained_variance_ratio': pca_model.explained_variance_ratio_.tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        save_results(results, output_dir / \"analysis_results.json\")\n",
    "        df_final.to_csv(output_dir / \"processed_data.csv\", index=False)\n",
    "\n",
    "        logger.log(\"分析流程完成！\")\n",
    "        logger.log(f\"结果保存在: {output_dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.log(f\"错误发生: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
